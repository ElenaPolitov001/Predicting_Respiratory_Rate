{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Random Forest Performance</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this script is to demonstrate the performance of Random Forest Regressor on the data.\n",
    "We display the histogram of errors on the training and testing sets. We then plot a graph to show the importance of each feature in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from joblib import dump, load\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first retrain the random forest regressor model that had the strongest performance in the model comparisons notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('person_csvs/all_people.csv', index_col=0)\n",
    "resp = [i for i in data.columns if 'RESP' in i and i!=' RESP']\n",
    "data.drop(resp+['Time [s]','sec'], axis=1, inplace=True)\n",
    "\n",
    "SS = StandardScaler()\n",
    "X = data.drop(' RESP', axis=1)\n",
    "columns = X.columns\n",
    "SS.fit(X, y=None)\n",
    "y = data[' RESP'].values\n",
    "X = SS.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\n",
    "\n",
    "# Uncomment this line and comment the two below it if you wish to load a model\n",
    "# model = load('saved_models/RFF_joblib') \n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "print('MSE:', MSE)\n",
    "print('MAE:', MAE)\n",
    "print('R2:', R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell plots histograms of the testing set and training set errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_test = pd.DataFrame((y_pred - y_test)).dropna()\n",
    "errors_train = pd.DataFrame((y_pred_train - y_train)).dropna()\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Errors on test set - Distplot')\n",
    "sns.distplot(errors_test, hist=True, kde=False)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('frequency')\n",
    "plt.xlim(-0.4, 0.4)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Errors on train set - Distplot')\n",
    "sns.distplot(errors_train, hist=True, kde=False)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('frequency')\n",
    "plt.xlim(-0.4, 0.4)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the histograms of errors on both the train set and test set have very similar structures. The model is well fit. Note that the scales are slightly different due to the size differences in the test set and the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X, columns=columns)\n",
    "\n",
    "importances = model.feature_importances_\n",
    "std = np.std([model.feature_importances_ for tree in model.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "feature_importances = []\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. %s (%f)\" % (f + 1, X.columns[indices[f]], importances[indices[f]]))\n",
    "    feature_importances.append((X.columns[indices[f]], importances[indices[f]]))\n",
    "\n",
    "values = [i[1] for i in feature_importances]\n",
    "names = [i[0] for i in feature_importances]\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure(figsize=(20,12))\n",
    "plt.title(\"Random Forest Feature importances\", fontsize=20)\n",
    "plt.barh(range(len(names)), values, color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.yticks(range(len(names)), names, fontsize=15)\n",
    "plt.xticks(np.linspace(0, max(importances), 30), rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
