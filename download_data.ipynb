{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading and formatting the data\n",
    "\n",
    "The purpose of this notebook is to download the raw data and put them into appropriate folders and .csvs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from os import listdir, mkdir\n",
    "from os.path import isdir, isfile, join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Download the data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 'https://physionet.org/physiobank/database/bidmc/bidmc_csv/'\n",
    "endings = ['_Breaths.csv','_Numerics.csv','_Signals.csv','_Fix.txt']\n",
    "\n",
    "files = {}\n",
    "\n",
    "nums = []\n",
    "for n in range(1,54):\n",
    "    if n<10:\n",
    "        nums.append('0'+str(n))\n",
    "    else:\n",
    "        nums.append(str(n))\n",
    "        \n",
    "for n in nums:\n",
    "    files[n] = ['bidmc_'+n+ending for ending in endings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:00<00:00, 190486.81it/s]\n"
     ]
    }
   ],
   "source": [
    "csv = {}\n",
    "txt = {}\n",
    "for number in tqdm(files.keys()):\n",
    "    csv[number] = []\n",
    "    for f in files[number]:\n",
    "        if 'csv' in f:\n",
    "            csv[number].append(base+f)\n",
    "        else:\n",
    "            txt[number] = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:53<00:00,  1.01it/s]\n"
     ]
    }
   ],
   "source": [
    "for f in tqdm(files.keys()):\n",
    "    for n in files[f]:\n",
    "        if '.txt' not in n:\n",
    "            df = pd.read_csv(base+n)\n",
    "            if not isdir(\"csv\"):\n",
    "                mkdir(\"csv\")\n",
    "            df.to_csv('csv/'+n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:03<00:00, 13.60it/s]\n"
     ]
    }
   ],
   "source": [
    "for n in tqdm(txt.keys()): \n",
    "    text = requests.get(base+txt[n])\n",
    "    text = text.text\n",
    "    if not isdir(\"txt\"):\n",
    "        mkdir(\"txt\")\n",
    "    with open('txt/'+txt[n], \"w\") as text_file:\n",
    "        text_file.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Combine data into individual persons</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataframe(num):\n",
    "    signals= pd.read_csv('csv/bidmc_'+str(num)+'_Signals.csv',index_col=0)\n",
    "    signals['sec'] = signals['Time [s]'].apply(lambda x: int(np.floor(x)))\n",
    "    numerics = pd.read_csv('csv/bidmc_'+str(num)+'_Numerics.csv',index_col=0)\n",
    "    numerics.fillna(numerics.mean(),inplace=True) \n",
    "    numerics.rename(columns={'Time [s]':'sec'},inplace=True)\n",
    "    numerics.drop(' RESP',axis=1,inplace=True)\n",
    "    numerics['sec'] = numerics['sec'].apply(lambda x: int(x))\n",
    "    signals = signals[[' RESP', ' PLETH', ' V', ' AVR', ' II','sec','Time [s]']]\n",
    "    person = signals.merge(numerics,on='sec',how='outer')\n",
    "    Hz_125_cols = [' RESP', ' PLETH', ' V', ' AVR', ' II']\n",
    "    Min = person[Hz_125_cols+['sec']].groupby('sec').min()\n",
    "    Min.columns = [i+'_Min' for i in Min.columns]\n",
    "    Max = person[Hz_125_cols+['sec']].groupby('sec').max()\n",
    "    Max.columns = [i+'_Max' for i in Max.columns]\n",
    "    Mean = person[Hz_125_cols+['sec']].groupby('sec').mean()\n",
    "    Mean.columns = Mean.columns = [i+'_Mean' for i in Mean.columns]\n",
    "    Kurt = person[Hz_125_cols+['sec']].groupby('sec').agg(lambda x: kurtosis(x))\n",
    "    Kurt.columns = [i+'_Kurt' for i in Kurt.columns]\n",
    "    Skw = person[Hz_125_cols+['sec']].groupby('sec').agg(lambda x: skew(x))\n",
    "    Skw.columns = [i+'_Skw' for i in Skw.columns]\n",
    "    summary_frames = [Min,Max,Mean,Kurt,Skw]\n",
    "    one_sec_summary = pd.concat(summary_frames,axis=1).reset_index()\n",
    "    person = person.merge(one_sec_summary,on='sec',how='outer')\n",
    "    if not isdir(\"person_csvs\"):\n",
    "        mkdir(\"person_csvs\")\n",
    "    person.to_csv('person_csvs/person_'+str(num)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = []\n",
    "for n in range(1,54):\n",
    "    if n<10:\n",
    "        nums.append('0'+str(n))\n",
    "    else:\n",
    "        nums.append(str(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring person 09 due to error\n",
      "Ignoring person 15 due to error\n",
      "Ignoring person 30 due to error\n"
     ]
    }
   ],
   "source": [
    "for number in nums:\n",
    "    try:\n",
    "        make_dataframe(number)\n",
    "    except:\n",
    "        print(\"Ignoring person\", number, \"due to error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Combine indivual persons data together</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfiles = [f for f in listdir('person_csvs') if isfile(join('person_csvs', f))]\n",
    "person_files = ['person_csvs/'+i for i in onlyfiles if 'person' in i]\n",
    "files = []\n",
    "for person in tqdm(person_files):\n",
    "    df = pd.read_csv(person,index_col=0)\n",
    "    files.append(df)\n",
    "\n",
    "df = pd.concat(files, axis=0, ignore_index=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('person_csvs/all_people.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
